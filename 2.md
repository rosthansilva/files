ðŸš€ Azure CosmosDB Dump Composite Action
This repository contains a GitHub Composite Action that:

âœ… Creates an Azure Data Factory
âœ… Creates an Azure Storage Account and a container
âœ… Configures Linked Services for CosmosDB and Storage
âœ… Creates a Data Factory pipeline to export CosmosDB data
âœ… Uses GitHub Actions for automation

ðŸ“Œ 1. Repository Structure
bash
Copiar
Editar
ðŸ“‚ .github/actions/azure-cosmos-dump/
 â”œâ”€â”€ ðŸ“„ action.yml       # Defines the Composite Action
 â”œâ”€â”€ ðŸ“„ entrypoint.sh    # Execution script
ðŸ”§ 2. Creating the Composite Action
Create the file .github/actions/azure-cosmos-dump/action.yml:

yaml
Copiar
Editar
name: "Azure Cosmos DB Dump"
description: "Creates a Data Factory, Storage Account, and performs a dump of CosmosDB using Data Factory"
inputs:
  resource_group:
    description: "Resource Group name"
    required: true
  location:
    description: "Azure region (e.g., eastus)"
    required: true
  datafactory_name:
    description: "Azure Data Factory name"
    required: true
  storage_account_name:
    description: "Storage Account name"
    required: true
  container_name:
    description: "Storage Account container name"
    required: true
  cosmosdb_account_name:
    description: "CosmosDB account name"
    required: true
  cosmosdb_database_name:
    description: "CosmosDB database name"
    required: true
  cosmosdb_container_name:
    description: "CosmosDB container name"
    required: true
  cosmosdb_account_key:
    description: "CosmosDB access key"
    required: true
runs:
  using: "composite"
  steps:
    - name: Authenticate with Azure
      run: az login --identity || az login
      shell: bash

    - name: Run the setup script
      run: |
        chmod +x $GITHUB_ACTION_PATH/entrypoint.sh
        $GITHUB_ACTION_PATH/entrypoint.sh
      shell: bash
      env:
        RESOURCE_GROUP: ${{ inputs.resource_group }}
        LOCATION: ${{ inputs.location }}
        DATAFACTORY_NAME: ${{ inputs.datafactory_name }}
        STORAGE_ACCOUNT_NAME: ${{ inputs.storage_account_name }}
        CONTAINER_NAME: ${{ inputs.container_name }}
        COSMOSDB_ACCOUNT_NAME: ${{ inputs.cosmosdb_account_name }}
        COSMOSDB_DATABASE_NAME: ${{ inputs.cosmosdb_database_name }}
        COSMOSDB_CONTAINER_NAME: ${{ inputs.cosmosdb_container_name }}
        COSMOSDB_ACCOUNT_KEY: ${{ inputs.cosmosdb_account_key }}
ðŸ›  3. Creating the Execution Script
Create the file .github/actions/azure-cosmos-dump/entrypoint.sh:

bash
Copiar
Editar
#!/bin/bash
set -e

echo "ðŸ”¹ Logging into Azure..."
az login --identity || az login

echo "ðŸ”¹ Creating Resource Group: $RESOURCE_GROUP"
az group create --name "$RESOURCE_GROUP" --location "$LOCATION"

echo "ðŸ”¹ Creating Storage Account: $STORAGE_ACCOUNT_NAME"
az storage account create \
    --name "$STORAGE_ACCOUNT_NAME" \
    --resource-group "$RESOURCE_GROUP" \
    --location "$LOCATION" \
    --sku Standard_LRS

STORAGE_KEY=$(az storage account keys list --account-name "$STORAGE_ACCOUNT_NAME" --resource-group "$RESOURCE_GROUP" --query "[0].value" -o tsv)

echo "ðŸ”¹ Creating Storage Container: $CONTAINER_NAME"
az storage container create \
    --name "$CONTAINER_NAME" \
    --account-name "$STORAGE_ACCOUNT_NAME" \
    --account-key "$STORAGE_KEY"

echo "ðŸ”¹ Creating Data Factory: $DATAFACTORY_NAME"
az datafactory create \
    --resource-group "$RESOURCE_GROUP" \
    --location "$LOCATION" \
    --name "$DATAFACTORY_NAME"

echo "ðŸ”¹ Creating CosmosDB Linked Service"
az datafactory linked-service create \
    --resource-group "$RESOURCE_GROUP" \
    --factory-name "$DATAFACTORY_NAME" \
    --name "CosmosDBLinkedService" \
    --properties "{\"type\":\"AzureCosmosDB\", \"typeProperties\":{\"connectionString\":\"AccountEndpoint=https://${COSMOSDB_ACCOUNT_NAME}.documents.azure.com:443/;AccountKey=${COSMOSDB_ACCOUNT_KEY};\"}}"

echo "ðŸ”¹ Creating Storage Linked Service"
az datafactory linked-service create \
    --resource-group "$RESOURCE_GROUP" \
    --factory-name "$DATAFACTORY_NAME" \
    --name "StorageLinkedService" \
    --properties "{\"type\":\"AzureBlobStorage\", \"typeProperties\":{\"connectionString\":\"DefaultEndpointsProtocol=https;AccountName=${STORAGE_ACCOUNT_NAME};AccountKey=${STORAGE_KEY};EndpointSuffix=core.windows.net\"}}"

echo "ðŸ”¹ Creating Data Factory Pipeline for CosmosDB Dump"
az datafactory pipeline create \
    --resource-group "$RESOURCE_GROUP" \
    --factory-name "$DATAFACTORY_NAME" \
    --name "CosmosDBDumpPipeline" \
    --properties '{
      "activities": [
        {
          "name": "CopyFromCosmosToBlob",
          "type": "Copy",
          "inputs": [{ "referenceName": "CosmosDBDataset", "type": "DatasetReference" }],
          "outputs": [{ "referenceName": "BlobDataset", "type": "DatasetReference" }],
          "typeProperties": {
            "source": { "type": "CosmosDbSource" },
            "sink": { "type": "BlobSink" }
          }
        }
      ]
    }'

echo "âœ… Azure CosmosDB Dump Pipeline is successfully created!"
ðŸš€ 4. Using the Composite Action in a GitHub Workflow
To use this action inside a GitHub Actions workflow, create .github/workflows/azure-cosmos-dump.yml:

yaml
Copiar
Editar
name: "Azure Cosmos DB Dump"

on:
  workflow_dispatch:

jobs:
  cosmosdb-dump:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Run Azure CosmosDB Dump Action
        uses: ./.github/actions/azure-cosmos-dump
        with:
          resource_group: "my-resource-group"
          location: "eastus"
          datafactory_name: "my-datafactory"
          storage_account_name: "mystorageaccount"
          container_name: "cosmos-dump-container"
          cosmosdb_account_name: "mycosmosdbaccount"
          cosmosdb_database_name: "mydatabase"
          cosmosdb_container_name: "mycontainer"
          cosmosdb_account_key: ${{ secrets.COSMOSDB_KEY }}
ðŸŽ¯ 5. How It Works
The GitHub Action logs in to Azure.

It creates an Azure Storage Account and a container.

It creates an Azure Data Factory instance.

It configures Linked Services for CosmosDB and Storage.

It creates a Data Factory Pipeline to extract data from CosmosDB and store it in Azure Blob Storage.

The action is triggered via GitHub Actions.

ðŸ”‘ 6. Secrets and Authentication
Ensure you store the CosmosDB Account Key in GitHub Secrets (COSMOSDB_KEY) to keep it secure.

ðŸ“Œ 7. Conclusion
This Composite Action allows you to automate CosmosDB data exports using Azure Data Factory. ðŸš€ It integrates seamlessly into GitHub Actions, making data backups and migrations effortless!

Would you like any improvements or additional configurations? ðŸ˜Š
